{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 包括6万张28x28的训练样本，1万张测试样本，可以说是CV里的“Hello Word”。这里使用的CNN网络将MNIST数据的识别率提高到了99%。下面我们就开始进行实战。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试gpu环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnFunction\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义超参数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =512 #设置每一个batch的数量为512\n",
    "num_epochs =20  # 训练20次\n",
    "#learning_rate = 1e-4    # 学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"data\", train=True, download=True, \n",
    "            transform=transforms.Compose([\n",
    "              transforms.ToTensor(), # 将输入转换为Tensor的格式\n",
    "              transforms.Normalize((0.1307,), (0.3081,)) # 用transforms.Normalize对数据进行归一化，参数为数据的平均数和标准差\n",
    "            ])),\n",
    "    batch_size=batch_size , shuffle=True) # suffle打乱\n",
    "\n",
    "# 加载测试集，按相同的方法\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"data\", train=False, transform=transforms.Compose([\n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])),\n",
    "    batch_size=batch_size , shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包含两个卷积层，第一层卷积核大小5*5，个数10；第二层卷积核大小3*3，个数20，步长均为1\n",
    "# 卷积层输出使用relu激活函数处理\n",
    "# 处理后用2*2的最大值池化，步长为1\n",
    "# 最后用两个全连接层，第一个输入节点数量20*10*10，输出节点数量500；第二个输入节点数量500，输出节点数量10（即对应10分类）\n",
    "class ConvNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv_layer1=nn.Conv2d(1,10,5) # input:(1,28,28) output:(10,24,24) \n",
    "    self.conv_layer2=nn.Conv2d(10,20,3) # input:(10,12,12) output:(20,10,10)\n",
    "    self.full_connected_layer1 = nn.Linear(20*10*10,500)\n",
    "    self.full_connected_layer2 = nn.Linear(500,10)\n",
    "  def forward(self,x): # 前向计算数值\n",
    "    in_size = x.size(0)\n",
    "    out = self.conv_layer1(x)\n",
    "    out = nnFunction.relu(out)\n",
    "    out = nnFunction.max_pool2d(out, 2, 2) \n",
    "    out = self.conv_layer2(out)\n",
    "    out = nnFunction.relu(out)\n",
    "    out = out.view(in_size,-1)\n",
    "    out = self.full_connected_layer1(out)\n",
    "    out = nnFunction.relu(out)\n",
    "    out = self.full_connected_layer2(out)\n",
    "    out = nnFunction.log_softmax(out,dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例化神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # 根据电脑配置自动选择使用cpu或者gpu\n",
    "model = ConvNet().to(DEVICE) # 将网络移动到gpu上\n",
    "optimizer = optim.Adam(model.parameters()) # 使用Adam优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用到反向传播，Adam优化训练\n",
    "def train(model, device, train_loader, optimizer, num_epochs):\n",
    "  model.train()\n",
    "  for batch_index, (data, target) in enumerate(train_loader):\n",
    "    # 取数据\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    # 先清空所有参数的梯度缓存，否则会在上面累加\n",
    "    optimizer.zero_grad()\n",
    "    # 向网络中输入images，得到output,在这一步的时候模型会自动调用model.forward(images)函数 \n",
    "    output = model(data)\n",
    "     # 计算损失\n",
    "    loss = nnFunction.nll_loss(output, target)\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    # 更新梯度\n",
    "    optimizer.step()\n",
    "    if(batch_index+1)%30 == 0: \n",
    "      print(\"Train Epoch_{} [{}/{} ({:.0f}%)]\tLoss: {:.6f}\".format(\n",
    "        num_epochs, batch_index * len(data), len(train_loader.dataset),\n",
    "        100. * batch_index / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "  #将模型设为评估模式，在模型中禁用dropout或者batch normalization层\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output = model(data)\n",
    "      test_loss += nnFunction.nll_loss(output, target, reduction=\"sum\").item() # 将一批的损失相加\n",
    "      pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  print(\"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\".format(test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_1 [14848/60000 (25%)]\tLoss: 0.335933\n",
      "Train Epoch_1 [30208/60000 (50%)]\tLoss: 0.175740\n",
      "Train Epoch_1 [45568/60000 (75%)]\tLoss: 0.109266\n",
      "Test set: Average loss: 0.0935, Accuracy: 9720/10000 (97.20%)\n",
      "\n",
      "Train Epoch_2 [14848/60000 (25%)]\tLoss: 0.085706\n",
      "Train Epoch_2 [30208/60000 (50%)]\tLoss: 0.065310\n",
      "Train Epoch_2 [45568/60000 (75%)]\tLoss: 0.051445\n",
      "Test set: Average loss: 0.0610, Accuracy: 9814/10000 (98.14%)\n",
      "\n",
      "Train Epoch_3 [14848/60000 (25%)]\tLoss: 0.047987\n",
      "Train Epoch_3 [30208/60000 (50%)]\tLoss: 0.070711\n",
      "Train Epoch_3 [45568/60000 (75%)]\tLoss: 0.038674\n",
      "Test set: Average loss: 0.0466, Accuracy: 9837/10000 (98.37%)\n",
      "\n",
      "Train Epoch_4 [14848/60000 (25%)]\tLoss: 0.036047\n",
      "Train Epoch_4 [30208/60000 (50%)]\tLoss: 0.038292\n",
      "Train Epoch_4 [45568/60000 (75%)]\tLoss: 0.033026\n",
      "Test set: Average loss: 0.0368, Accuracy: 9874/10000 (98.74%)\n",
      "\n",
      "Train Epoch_5 [14848/60000 (25%)]\tLoss: 0.030731\n",
      "Train Epoch_5 [30208/60000 (50%)]\tLoss: 0.029835\n",
      "Train Epoch_5 [45568/60000 (75%)]\tLoss: 0.031285\n",
      "Test set: Average loss: 0.0331, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch_6 [14848/60000 (25%)]\tLoss: 0.016946\n",
      "Train Epoch_6 [30208/60000 (50%)]\tLoss: 0.015190\n",
      "Train Epoch_6 [45568/60000 (75%)]\tLoss: 0.017407\n",
      "Test set: Average loss: 0.0322, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch_7 [14848/60000 (25%)]\tLoss: 0.014275\n",
      "Train Epoch_7 [30208/60000 (50%)]\tLoss: 0.014660\n",
      "Train Epoch_7 [45568/60000 (75%)]\tLoss: 0.009270\n",
      "Test set: Average loss: 0.0372, Accuracy: 9867/10000 (98.67%)\n",
      "\n",
      "Train Epoch_8 [14848/60000 (25%)]\tLoss: 0.013106\n",
      "Train Epoch_8 [30208/60000 (50%)]\tLoss: 0.009811\n",
      "Train Epoch_8 [45568/60000 (75%)]\tLoss: 0.013609\n",
      "Test set: Average loss: 0.0328, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch_9 [14848/60000 (25%)]\tLoss: 0.005687\n",
      "Train Epoch_9 [30208/60000 (50%)]\tLoss: 0.007915\n",
      "Train Epoch_9 [45568/60000 (75%)]\tLoss: 0.009482\n",
      "Test set: Average loss: 0.0401, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch_10 [14848/60000 (25%)]\tLoss: 0.003567\n",
      "Train Epoch_10 [30208/60000 (50%)]\tLoss: 0.007150\n",
      "Train Epoch_10 [45568/60000 (75%)]\tLoss: 0.002996\n",
      "Test set: Average loss: 0.0390, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch_11 [14848/60000 (25%)]\tLoss: 0.002820\n",
      "Train Epoch_11 [30208/60000 (50%)]\tLoss: 0.015303\n",
      "Train Epoch_11 [45568/60000 (75%)]\tLoss: 0.022288\n",
      "Test set: Average loss: 0.0353, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch_12 [14848/60000 (25%)]\tLoss: 0.002690\n",
      "Train Epoch_12 [30208/60000 (50%)]\tLoss: 0.005309\n",
      "Train Epoch_12 [45568/60000 (75%)]\tLoss: 0.013069\n",
      "Test set: Average loss: 0.0365, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch_13 [14848/60000 (25%)]\tLoss: 0.008641\n",
      "Train Epoch_13 [30208/60000 (50%)]\tLoss: 0.006823\n",
      "Train Epoch_13 [45568/60000 (75%)]\tLoss: 0.002234\n",
      "Test set: Average loss: 0.0401, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch_14 [14848/60000 (25%)]\tLoss: 0.006396\n",
      "Train Epoch_14 [30208/60000 (50%)]\tLoss: 0.007520\n",
      "Train Epoch_14 [45568/60000 (75%)]\tLoss: 0.002420\n",
      "Test set: Average loss: 0.0410, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch_15 [14848/60000 (25%)]\tLoss: 0.002979\n",
      "Train Epoch_15 [30208/60000 (50%)]\tLoss: 0.001652\n",
      "Train Epoch_15 [45568/60000 (75%)]\tLoss: 0.001320\n",
      "Test set: Average loss: 0.0372, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch_16 [14848/60000 (25%)]\tLoss: 0.000329\n",
      "Train Epoch_16 [30208/60000 (50%)]\tLoss: 0.002767\n",
      "Train Epoch_16 [45568/60000 (75%)]\tLoss: 0.003366\n",
      "Test set: Average loss: 0.0426, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch_17 [14848/60000 (25%)]\tLoss: 0.000556\n",
      "Train Epoch_17 [30208/60000 (50%)]\tLoss: 0.007269\n",
      "Train Epoch_17 [45568/60000 (75%)]\tLoss: 0.003087\n",
      "Test set: Average loss: 0.0376, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "Train Epoch_18 [14848/60000 (25%)]\tLoss: 0.006409\n",
      "Train Epoch_18 [30208/60000 (50%)]\tLoss: 0.001271\n",
      "Train Epoch_18 [45568/60000 (75%)]\tLoss: 0.002770\n",
      "Test set: Average loss: 0.0420, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch_19 [14848/60000 (25%)]\tLoss: 0.005574\n",
      "Train Epoch_19 [30208/60000 (50%)]\tLoss: 0.002800\n",
      "Train Epoch_19 [45568/60000 (75%)]\tLoss: 0.000285\n",
      "Test set: Average loss: 0.0446, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch_20 [14848/60000 (25%)]\tLoss: 0.011634\n",
      "Train Epoch_20 [30208/60000 (50%)]\tLoss: 0.003629\n",
      "Train Epoch_20 [45568/60000 (75%)]\tLoss: 0.019833\n",
      "Test set: Average loss: 0.0459, Accuracy: 9879/10000 (98.79%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs  + 1):\n",
    "  train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "  test(model, DEVICE, test_loader)\n",
    "  print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit1c018faca67a42dd982418517459a13a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
