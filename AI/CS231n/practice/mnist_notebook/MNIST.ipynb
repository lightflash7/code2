{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 包括6万张28x28的训练样本，1万张测试样本，可以说是CV里的“Hello Word”。这里使用的CNN网络将MNIST数据的识别率提高到了99%。下面我们就开始进行实战。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试gpu环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnFunction\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义超参数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =512 #设置每一个batch的数量为512\n",
    "num_epochs =20  # 训练20次\n",
    "#learning_rate = 1e-4    # 学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"data\", train=True, download=True, \n",
    "            transform=transforms.Compose([\n",
    "              transforms.ToTensor(), # 将输入转换为Tensor的格式\n",
    "              transforms.Normalize((0.1307,), (0.3081,)) # 用transforms.Normalize对数据进行归一化，参数为数据的平均数和标准差\n",
    "            ])),\n",
    "    batch_size=batch_size , shuffle=True) # suffle打乱\n",
    "\n",
    "# 加载测试集，按相同的方法\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"data\", train=False, transform=transforms.Compose([\n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])),\n",
    "    batch_size=batch_size , shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包含两个卷积层，第一层卷积核大小5*5，个数10；第二层卷积核大小3*3，个数20，步长均为1\n",
    "# 卷积层输出使用relu激活函数处理\n",
    "# 处理后用2*2的最大值池化，步长为1\n",
    "# 最后用两个全连接层，第一个输入节点数量20*10*10，输出节点数量500；第二个输入节点数量500，输出节点数量10（即对应10分类）\n",
    "class ConvNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv_layer1=nn.Conv2d(1,6,5) # input:(1,28,28) output:(6,24,24) \n",
    "    self.conv_layer2=nn.Conv2d(10,16,3) # input:(10,12,12) output:(20,10,10)\n",
    "    self.full_connected_layer1 = nn.Linear(16*10*10,500)\n",
    "    self.full_connected_layer2 = nn.Linear(500,10)\n",
    "  def forward(self,x): # 前向计算数值\n",
    "    in_size = x.size(0)\n",
    "    out = self.conv_layer1(x)\n",
    "    out = nnFunction.relu(out)\n",
    "    out = nnFunction.max_pool2d(out, 2, 2) \n",
    "    out = self.conv_layer2(out)\n",
    "    out = nnFunction.relu(out)\n",
    "    out = out.view(in_size,-1)\n",
    "    out = self.full_connected_layer1(out)\n",
    "    out = nnFunction.relu(out)\n",
    "    out = self.full_connected_layer2(out)\n",
    "    out = nnFunction.log_softmax(out,dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例化神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # 根据电脑配置自动选择使用cpu或者gpu\n",
    "model = ConvNet().to(DEVICE) # 将网络移动到gpu上\n",
    "optimizer = optim.Adam(model.parameters()) # 使用Adam优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用到反向传播，Adam优化训练\n",
    "def train(model, device, train_loader, optimizer, num_epochs):\n",
    "  model.train()\n",
    "  for batch_index, (data, target) in enumerate(train_loader):\n",
    "    # 取数据\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    # 先清空所有参数的梯度缓存，否则会在上面累加\n",
    "    optimizer.zero_grad()\n",
    "    # 向网络中输入images，得到output,在这一步的时候模型会自动调用model.forward(images)函数 \n",
    "    output = model(data)\n",
    "     # 计算损失\n",
    "    loss = nnFunction.nll_loss(output, target)\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    # 更新梯度\n",
    "    optimizer.step()\n",
    "    if(batch_index+1)%30 == 0: \n",
    "      print(\"Train Epoch_{} [{}/{} ({:.0f}%)]\tLoss: {:.6f}\".format(\n",
    "        num_epochs, batch_index * len(data), len(train_loader.dataset),\n",
    "        100. * batch_index / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练集准确率计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_accuracy(model, device, train_loader):\n",
    "  #将模型设为评估模式，在模型中禁用dropout或者batch normalization层\n",
    "  model.eval()\n",
    "  train_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in train_loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output = model(data)\n",
    "      train_loss += nnFunction.nll_loss(output, target, reduction=\"sum\").item() # 将一批的损失相加\n",
    "      pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "  train_loss /= len(train_loader.dataset)\n",
    "  print(\"train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\".format(train_loss, correct, len(train_loader.dataset),100. * correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义测试集测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "  #将模型设为评估模式，在模型中禁用dropout或者batch normalization层\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output = model(data)\n",
    "      test_loss += nnFunction.nll_loss(output, target, reduction=\"sum\").item() # 将一批的损失相加\n",
    "      pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  print(\"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\".format(test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_1 [14848/60000 (25%)]\tLoss: 0.290438\n",
      "Train Epoch_1 [30208/60000 (50%)]\tLoss: 0.193169\n",
      "Train Epoch_1 [45568/60000 (75%)]\tLoss: 0.142141\n",
      "train set: Average loss: 0.0974, Accuracy: 58297/60000 (97.16%)\n",
      "Test set: Average loss: 0.0898, Accuracy: 9721/10000 (97.21%)\n",
      "\n",
      "Train Epoch_2 [14848/60000 (25%)]\tLoss: 0.067529\n",
      "Train Epoch_2 [30208/60000 (50%)]\tLoss: 0.072156\n",
      "Train Epoch_2 [45568/60000 (75%)]\tLoss: 0.089861\n",
      "train set: Average loss: 0.0661, Accuracy: 58754/60000 (97.92%)\n",
      "Test set: Average loss: 0.0598, Accuracy: 9804/10000 (98.04%)\n",
      "\n",
      "Train Epoch_3 [14848/60000 (25%)]\tLoss: 0.085427\n",
      "Train Epoch_3 [30208/60000 (50%)]\tLoss: 0.064826\n",
      "Train Epoch_3 [45568/60000 (75%)]\tLoss: 0.057574\n",
      "train set: Average loss: 0.0406, Accuracy: 59302/60000 (98.84%)\n",
      "Test set: Average loss: 0.0478, Accuracy: 9844/10000 (98.44%)\n",
      "\n",
      "Train Epoch_4 [14848/60000 (25%)]\tLoss: 0.038545\n",
      "Train Epoch_4 [30208/60000 (50%)]\tLoss: 0.043670\n",
      "Train Epoch_4 [45568/60000 (75%)]\tLoss: 0.031260\n",
      "train set: Average loss: 0.0340, Accuracy: 59377/60000 (98.96%)\n",
      "Test set: Average loss: 0.0463, Accuracy: 9846/10000 (98.46%)\n",
      "\n",
      "Train Epoch_5 [14848/60000 (25%)]\tLoss: 0.037690\n",
      "Train Epoch_5 [30208/60000 (50%)]\tLoss: 0.052165\n",
      "Train Epoch_5 [45568/60000 (75%)]\tLoss: 0.043942\n",
      "train set: Average loss: 0.0242, Accuracy: 59561/60000 (99.27%)\n",
      "Test set: Average loss: 0.0360, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "Train Epoch_6 [14848/60000 (25%)]\tLoss: 0.014468\n",
      "Train Epoch_6 [30208/60000 (50%)]\tLoss: 0.019137\n",
      "Train Epoch_6 [45568/60000 (75%)]\tLoss: 0.018962\n",
      "train set: Average loss: 0.0188, Accuracy: 59679/60000 (99.47%)\n",
      "Test set: Average loss: 0.0324, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch_7 [14848/60000 (25%)]\tLoss: 0.016077\n",
      "Train Epoch_7 [30208/60000 (50%)]\tLoss: 0.018737\n",
      "Train Epoch_7 [45568/60000 (75%)]\tLoss: 0.015420\n",
      "train set: Average loss: 0.0197, Accuracy: 59618/60000 (99.36%)\n",
      "Test set: Average loss: 0.0391, Accuracy: 9872/10000 (98.72%)\n",
      "\n",
      "Train Epoch_8 [14848/60000 (25%)]\tLoss: 0.018141\n",
      "Train Epoch_8 [30208/60000 (50%)]\tLoss: 0.015090\n",
      "Train Epoch_8 [45568/60000 (75%)]\tLoss: 0.016096\n",
      "train set: Average loss: 0.0089, Accuracy: 59861/60000 (99.77%)\n",
      "Test set: Average loss: 0.0288, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch_9 [14848/60000 (25%)]\tLoss: 0.004724\n",
      "Train Epoch_9 [30208/60000 (50%)]\tLoss: 0.010183\n",
      "Train Epoch_9 [45568/60000 (75%)]\tLoss: 0.016274\n",
      "train set: Average loss: 0.0096, Accuracy: 59836/60000 (99.73%)\n",
      "Test set: Average loss: 0.0367, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch_10 [14848/60000 (25%)]\tLoss: 0.025033\n",
      "Train Epoch_10 [30208/60000 (50%)]\tLoss: 0.008292\n",
      "Train Epoch_10 [45568/60000 (75%)]\tLoss: 0.009496\n",
      "train set: Average loss: 0.0081, Accuracy: 59866/60000 (99.78%)\n",
      "Test set: Average loss: 0.0335, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch_11 [14848/60000 (25%)]\tLoss: 0.004141\n",
      "Train Epoch_11 [30208/60000 (50%)]\tLoss: 0.021789\n",
      "Train Epoch_11 [45568/60000 (75%)]\tLoss: 0.008777\n",
      "train set: Average loss: 0.0059, Accuracy: 59915/60000 (99.86%)\n",
      "Test set: Average loss: 0.0339, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch_12 [14848/60000 (25%)]\tLoss: 0.004951\n",
      "Train Epoch_12 [30208/60000 (50%)]\tLoss: 0.006071\n",
      "Train Epoch_12 [45568/60000 (75%)]\tLoss: 0.006203\n",
      "train set: Average loss: 0.0045, Accuracy: 59933/60000 (99.89%)\n",
      "Test set: Average loss: 0.0411, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch_13 [14848/60000 (25%)]\tLoss: 0.003076\n",
      "Train Epoch_13 [30208/60000 (50%)]\tLoss: 0.001404\n",
      "Train Epoch_13 [45568/60000 (75%)]\tLoss: 0.027369\n",
      "train set: Average loss: 0.0034, Accuracy: 59953/60000 (99.92%)\n",
      "Test set: Average loss: 0.0352, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch_14 [14848/60000 (25%)]\tLoss: 0.011489\n",
      "Train Epoch_14 [30208/60000 (50%)]\tLoss: 0.002027\n",
      "Train Epoch_14 [45568/60000 (75%)]\tLoss: 0.007787\n",
      "train set: Average loss: 0.0031, Accuracy: 59951/60000 (99.92%)\n",
      "Test set: Average loss: 0.0364, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch_15 [14848/60000 (25%)]\tLoss: 0.002207\n",
      "Train Epoch_15 [30208/60000 (50%)]\tLoss: 0.004939\n",
      "Train Epoch_15 [45568/60000 (75%)]\tLoss: 0.000858\n",
      "train set: Average loss: 0.0038, Accuracy: 59931/60000 (99.89%)\n",
      "Test set: Average loss: 0.0423, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch_16 [14848/60000 (25%)]\tLoss: 0.001366\n",
      "Train Epoch_16 [30208/60000 (50%)]\tLoss: 0.001618\n",
      "Train Epoch_16 [45568/60000 (75%)]\tLoss: 0.002804\n",
      "train set: Average loss: 0.0028, Accuracy: 59957/60000 (99.93%)\n",
      "Test set: Average loss: 0.0388, Accuracy: 9907/10000 (99.07%)\n",
      "\n",
      "Train Epoch_17 [14848/60000 (25%)]\tLoss: 0.002257\n",
      "Train Epoch_17 [30208/60000 (50%)]\tLoss: 0.002361\n",
      "Train Epoch_17 [45568/60000 (75%)]\tLoss: 0.010380\n",
      "train set: Average loss: 0.0018, Accuracy: 59976/60000 (99.96%)\n",
      "Test set: Average loss: 0.0388, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch_18 [14848/60000 (25%)]\tLoss: 0.001799\n",
      "Train Epoch_18 [30208/60000 (50%)]\tLoss: 0.000537\n",
      "Train Epoch_18 [45568/60000 (75%)]\tLoss: 0.009646\n",
      "train set: Average loss: 0.0011, Accuracy: 59990/60000 (99.98%)\n",
      "Test set: Average loss: 0.0385, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch_19 [14848/60000 (25%)]\tLoss: 0.001017\n",
      "Train Epoch_19 [30208/60000 (50%)]\tLoss: 0.000654\n",
      "Train Epoch_19 [45568/60000 (75%)]\tLoss: 0.001314\n",
      "train set: Average loss: 0.0016, Accuracy: 59976/60000 (99.96%)\n",
      "Test set: Average loss: 0.0388, Accuracy: 9909/10000 (99.09%)\n",
      "\n",
      "Train Epoch_20 [14848/60000 (25%)]\tLoss: 0.000659\n",
      "Train Epoch_20 [30208/60000 (50%)]\tLoss: 0.005240\n",
      "Train Epoch_20 [45568/60000 (75%)]\tLoss: 0.001026\n",
      "train set: Average loss: 0.0084, Accuracy: 59823/60000 (99.70%)\n",
      "Test set: Average loss: 0.0566, Accuracy: 9873/10000 (98.73%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs  + 1):\n",
    "  train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "  get_train_accuracy(model, DEVICE, train_loader)\n",
    "  test(model, DEVICE, test_loader)\n",
    "  print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit1c018faca67a42dd982418517459a13a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
