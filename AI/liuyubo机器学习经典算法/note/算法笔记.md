# 机器学习基本算法笔记

---

[toc]

## k-Nearest Neighbors

kNN算法相当于取当前要预测的点中，最近的k个邻居，看看最近的邻居中哪个类型最多，就预测当前点属于哪一类型。

![Snipaste_2020-02-28_20-46-35](F:\code2\AI\liuyubo机器学习经典算法\note\src\Snipaste_2020-02-28_20-46-35.png)



通常的，这个距离指的是欧氏距离，即
$$
d(x, y):=\sqrt{\left(x_{1}-y_{1}\right)^{2}+\left(x_{2}-y_{2}\right)^{2}+\cdots+\left(x_{n}-y_{n}\right)^{2}}=\sqrt{\sum_{i=1}^{n}\left(x_{i}-y_{i}\right)^{2}}
$$





可以看到的kNN参数k的特性是：
![Snipaste_2020-02-29_22-13-51](F:\code2\AI\liuyubo机器学习经典算法\note\src\Snipaste_2020-02-29_22-13-51.png)




>1. kNN算法可以说不需要训练
>
>2. 可以说是没有模型的算法，也可以把数据集本身当成kNN算法的模型。
>
>



### 能够解决的问题

- 多分类
- 回归



### 优缺点

#### 优点：

- 简单

#### 缺点：

- 效率低下：如果m个样本,n个特征，则预测新数据复杂度O(m*n)
- 高度数据相关
- 预测结果不具有可解释性
- 维数灾难

![Snipaste_2020-02-28_23-43-35](F:\code2\AI\liuyubo机器学习经典算法\note\src\Snipaste_2020-02-28_23-43-35.png)





### 权重？

距离是否考虑权重。

![Snipaste_2020-02-28_22-20-42](F:\code2\AI\liuyubo机器学习经典算法\note\src\Snipaste_2020-02-28_22-20-42.png)





### 距离？

曼哈顿距离  $\sum_{i=1}^{n}\left|X_{i}^{(a)}-X_{i}^{(b)}\right|$

欧拉距离  $\sqrt{\sum_{i=1}^{n}\left|X_{i}^{(a)}-X_{i}^{(b)}\right|^{2}}$

明可夫斯基距离  $\left(\sum_{i=1}^{n}\left|X_{i}^{(a)}-X_{i}^{(b)}\right|^{p}\right)^{\frac{1}{p}}$





### 超参数的概念

> 超参数：在算法运行前需要决定的参数
> 模型参数：算法过程中学习的参数

——所以kNN中的k即典型的超参数



超参数可以用网格搜索方法计算。